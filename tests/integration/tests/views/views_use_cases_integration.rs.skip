//! ViewSet Use Cases Integration Tests
//!
//! Tests practical real-world use case scenarios:
//! - Blog posting system (create, publish, archive workflow)
//! - E-commerce product management (inventory, pricing, search)
//! - Task management system (create, status updates, completion)
//! - User profile management (update, privacy settings)
//! - Comment/Review system (nested resources, moderation)
//! - Category-based content management
//! - Multi-tenant resource isolation
//!
//! **Test Category**: Use Case Testing (ユースケーステスト)
//!
//! **Note**: These tests simulate real-world application workflows,
//! combining multiple operations to verify end-to-end functionality.

use bytes::Bytes;
use chrono::{DateTime, Utc};
use hyper::{HeaderMap, Method, StatusCode, Version};
use reinhardt_core::http::{Request, Response};
use reinhardt_test::fixtures::testcontainers::postgres_container;
use reinhardt_views::{CreateAPIView, ListAPIView, UpdateAPIView};
use rstest::*;
use sea_query::{Iden, PostgresQueryBuilder, Query, Table};
use serde::{Deserialize, Serialize};
use serial_test::serial;
use sqlx::{PgPool, Row};

// ============================================================================
// Test Models
// ============================================================================

/// Blog post model for publishing workflow
#[allow(dead_code)]
#[model(app_label = "usecase_test", table_name = "blog_posts")]
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
struct BlogPost {
	#[field(primary_key = true)]
	id: Option<i64>,
	#[field(max_length = 200)]
	title: String,
	#[field(max_length = 10000)]
	content: String,
	#[field(max_length = 50)]
	status: String, // draft, published, archived
	#[field(null = true)]
	author_id: Option<i64>,
	#[field(null = true)]
	published_at: Option<DateTime<Utc>>,
	#[field(null = true)]
	created_at: Option<DateTime<Utc>>,
}

/// Product model for e-commerce
#[allow(dead_code)]
#[model(app_label = "usecase_test", table_name = "products")]
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
struct Product {
	#[field(primary_key = true)]
	id: Option<i64>,
	#[field(max_length = 200)]
	name: String,
	#[field(max_length = 100)]
	sku: String,
	price: f64,
	stock_quantity: i32,
	#[field(max_length = 100)]
	category: String,
	active: bool,
}

/// Task model for project management
#[allow(dead_code)]
#[model(app_label = "usecase_test", table_name = "tasks")]
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
struct Task {
	#[field(primary_key = true)]
	id: Option<i64>,
	#[field(max_length = 200)]
	title: String,
	#[field(max_length = 5000)]
	description: String,
	#[field(max_length = 50)]
	status: String, // todo, in_progress, done
	priority: i32,
	#[field(null = true)]
	assignee_id: Option<i64>,
	#[field(null = true)]
	due_date: Option<DateTime<Utc>>,
}

// ============================================================================
// Iden Enums
// ============================================================================

#[derive(Iden)]
enum BlogPosts {
	Table,
	Id,
	Title,
	Content,
	Status,
	AuthorId,
	PublishedAt,
	CreatedAt,
}

#[derive(Iden)]
enum Products {
	Table,
	Id,
	Name,
	Sku,
	Price,
	StockQuantity,
	Category,
	Active,
}

#[derive(Iden)]
enum Tasks {
	Table,
	Id,
	Title,
	Description,
	Status,
	Priority,
	AssigneeId,
	DueDate,
}

// ============================================================================
// Fixtures
// ============================================================================

/// Setup: PostgreSQL container with blog posts schema
#[fixture]
async fn setup_blog() -> PgPool {
	let container = postgres_container().await;
	let pool = container.pool.clone();

	// Create blog_posts table
	let create_table_sql = Table::create()
		.table(BlogPosts::Table)
		.if_not_exists()
		.col(
			sea_query::ColumnDef::new(BlogPosts::Id)
				.big_integer()
				.not_null()
				.auto_increment()
				.primary_key(),
		)
		.col(
			sea_query::ColumnDef::new(BlogPosts::Title)
				.string_len(200)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(BlogPosts::Content)
				.string_len(10000)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(BlogPosts::Status)
				.string_len(50)
				.not_null(),
		)
		.col(sea_query::ColumnDef::new(BlogPosts::AuthorId).big_integer())
		.col(sea_query::ColumnDef::new(BlogPosts::PublishedAt).timestamp())
		.col(sea_query::ColumnDef::new(BlogPosts::CreatedAt).timestamp())
		.build(PostgresQueryBuilder);

	sqlx::query(&create_table_sql).execute(&pool).await.unwrap();

	pool
}

/// Setup: PostgreSQL container with products schema
#[fixture]
async fn setup_products() -> PgPool {
	let container = postgres_container().await;
	let pool = container.pool.clone();

	// Create products table
	let create_table_sql = Table::create()
		.table(Products::Table)
		.if_not_exists()
		.col(
			sea_query::ColumnDef::new(Products::Id)
				.big_integer()
				.not_null()
				.auto_increment()
				.primary_key(),
		)
		.col(
			sea_query::ColumnDef::new(Products::Name)
				.string_len(200)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Products::Sku)
				.string_len(100)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Products::Price)
				.double()
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Products::StockQuantity)
				.integer()
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Products::Category)
				.string_len(100)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Products::Active)
				.boolean()
				.not_null(),
		)
		.build(PostgresQueryBuilder);

	sqlx::query(&create_table_sql).execute(&pool).await.unwrap();

	pool
}

/// Setup: PostgreSQL container with tasks schema
#[fixture]
async fn setup_tasks() -> PgPool {
	let container = postgres_container().await;
	let pool = container.pool.clone();

	// Create tasks table
	let create_table_sql = Table::create()
		.table(Tasks::Table)
		.if_not_exists()
		.col(
			sea_query::ColumnDef::new(Tasks::Id)
				.big_integer()
				.not_null()
				.auto_increment()
				.primary_key(),
		)
		.col(
			sea_query::ColumnDef::new(Tasks::Title)
				.string_len(200)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Tasks::Description)
				.string_len(5000)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Tasks::Status)
				.string_len(50)
				.not_null(),
		)
		.col(
			sea_query::ColumnDef::new(Tasks::Priority)
				.integer()
				.not_null(),
		)
		.col(sea_query::ColumnDef::new(Tasks::AssigneeId).big_integer())
		.col(sea_query::ColumnDef::new(Tasks::DueDate).timestamp())
		.build(PostgresQueryBuilder);

	sqlx::query(&create_table_sql).execute(&pool).await.unwrap();

	pool
}

// ============================================================================
// Helper Functions
// ============================================================================

/// Helper: Create HTTP POST request with JSON body
fn create_post_request(uri: &str, body: &str) -> Request {
	let mut headers = HeaderMap::new();
	headers.insert(
		hyper::header::CONTENT_TYPE,
		"application/json".parse().unwrap(),
	);

	Request::builder()
		.method(Method::POST)
		.uri(uri)
		.version(Version::HTTP_11)
		.headers(headers)
		.body(Bytes::from(body.to_string()))
		.build()
		.expect("Failed to build request")
}

/// Helper: Create HTTP PUT request with JSON body
fn create_put_request(uri: &str, body: &str) -> Request {
	let mut headers = HeaderMap::new();
	headers.insert(
		hyper::header::CONTENT_TYPE,
		"application/json".parse().unwrap(),
	);

	Request::builder()
		.method(Method::PUT)
		.uri(uri)
		.version(Version::HTTP_11)
		.headers(headers)
		.body(Bytes::from(body.to_string()))
		.build()
		.expect("Failed to build request")
}

/// Helper: Create HTTP GET request
fn create_get_request(uri: &str) -> Request {
	Request::builder()
		.method(Method::GET)
		.uri(uri)
		.version(Version::HTTP_11)
		.headers(HeaderMap::new())
		.body(Bytes::new())
		.build()
		.expect("Failed to build request")
}

// ============================================================================
// Tests
// ============================================================================

/// Use Case 1: Blog posting workflow (draft → published → archived)
#[rstest]
#[tokio::test]
#[serial(views_usecases)]
async fn test_blog_posting_workflow(#[future] setup_blog: PgPool) {
	let pool = setup_blog.await;

	// Step 1: Create draft post
	let draft_post = BlogPost::new(
		"My First Blog Post".to_string(),
		"This is the content of my blog post.".to_string(),
		"draft".to_string(),
		Some(1),
		None,
		Some(Utc::now()),
	);

	let insert_sql = Query::insert()
		.into_table(BlogPosts::Table)
		.columns([
			BlogPosts::Title,
			BlogPosts::Content,
			BlogPosts::Status,
			BlogPosts::AuthorId,
			BlogPosts::PublishedAt,
			BlogPosts::CreatedAt,
		])
		.values_panic([
			draft_post.title.into(),
			draft_post.content.into(),
			draft_post.status.into(),
			draft_post.author_id.into(),
			draft_post.published_at.into(),
			draft_post.created_at.into(),
		])
		.returning_all()
		.build(PostgresQueryBuilder);

	let row = sqlx::query(&insert_sql).fetch_one(&pool).await.unwrap();
	let post_id: i64 = row.get("id");
	let status: String = row.get("status");

	assert_eq!(status, "draft");

	// Step 2: Publish post (update status and published_at)
	let publish_sql = Query::update()
		.table(BlogPosts::Table)
		.values([
			(BlogPosts::Status, "published".into()),
			(BlogPosts::PublishedAt, Utc::now().into()),
		])
		.and_where(sea_query::Expr::col(BlogPosts::Id).eq(post_id))
		.build(PostgresQueryBuilder);

	sqlx::query(&publish_sql).execute(&pool).await.unwrap();

	// Verify published status
	let select_sql = Query::select()
		.from(BlogPosts::Table)
		.columns([BlogPosts::Status, BlogPosts::PublishedAt])
		.and_where(sea_query::Expr::col(BlogPosts::Id).eq(post_id))
		.build(PostgresQueryBuilder);

	let published_row = sqlx::query(&select_sql).fetch_one(&pool).await.unwrap();
	let published_status: String = published_row.get("status");
	let published_at: Option<DateTime<Utc>> = published_row.get("published_at");

	assert_eq!(published_status, "published");
	assert!(published_at.is_some(), "published_at should be set");

	// Step 3: Archive post
	let archive_sql = Query::update()
		.table(BlogPosts::Table)
		.values([(BlogPosts::Status, "archived".into())])
		.and_where(sea_query::Expr::col(BlogPosts::Id).eq(post_id))
		.build(PostgresQueryBuilder);

	sqlx::query(&archive_sql).execute(&pool).await.unwrap();

	// Verify archived status
	let archived_row = sqlx::query(&select_sql).fetch_one(&pool).await.unwrap();
	let archived_status: String = archived_row.get("status");

	assert_eq!(archived_status, "archived");
}

/// Use Case 2: E-commerce inventory management
#[rstest]
#[tokio::test]
#[serial(views_usecases)]
async fn test_ecommerce_inventory_management(#[future] setup_products: PgPool) {
	let pool = setup_products.await;

	// Step 1: Add new product
	let product = Product::new(
		"Wireless Mouse".to_string(),
		"WM-001".to_string(),
		29.99,
		100,
		"Electronics".to_string(),
		true,
	);

	let insert_sql = Query::insert()
		.into_table(Products::Table)
		.columns([
			Products::Name,
			Products::Sku,
			Products::Price,
			Products::StockQuantity,
			Products::Category,
			Products::Active,
		])
		.values_panic([
			product.name.into(),
			product.sku.into(),
			product.price.into(),
			product.stock_quantity.into(),
			product.category.into(),
			product.active.into(),
		])
		.returning_all()
		.build(PostgresQueryBuilder);

	let row = sqlx::query(&insert_sql).fetch_one(&pool).await.unwrap();
	let product_id: i64 = row.get("id");
	let initial_stock: i32 = row.get("stock_quantity");

	assert_eq!(initial_stock, 100);

	// Step 2: Simulate sale (decrease stock by 5)
	let new_stock = initial_stock - 5;
	let update_stock_sql = Query::update()
		.table(Products::Table)
		.values([(Products::StockQuantity, new_stock.into())])
		.and_where(sea_query::Expr::col(Products::Id).eq(product_id))
		.build(PostgresQueryBuilder);

	sqlx::query(&update_stock_sql).execute(&pool).await.unwrap();

	// Verify stock updated
	let select_sql = Query::select()
		.from(Products::Table)
		.column(Products::StockQuantity)
		.and_where(sea_query::Expr::col(Products::Id).eq(product_id))
		.build(PostgresQueryBuilder);

	let updated_row = sqlx::query(&select_sql).fetch_one(&pool).await.unwrap();
	let updated_stock: i32 = updated_row.get("stock_quantity");

	assert_eq!(updated_stock, 95);

	// Step 3: Deactivate product when out of stock
	let deactivate_sql = Query::update()
		.table(Products::Table)
		.values([
			(Products::StockQuantity, 0.into()),
			(Products::Active, false.into()),
		])
		.and_where(sea_query::Expr::col(Products::Id).eq(product_id))
		.build(PostgresQueryBuilder);

	sqlx::query(&deactivate_sql).execute(&pool).await.unwrap();

	// Verify deactivated
	let final_row = sqlx::query(&select_sql).fetch_one(&pool).await.unwrap();
	let final_stock: i32 = final_row.get("stock_quantity");

	assert_eq!(final_stock, 0);
}

/// Use Case 3: Task management system workflow
#[rstest]
#[tokio::test]
#[serial(views_usecases)]
async fn test_task_management_workflow(#[future] setup_tasks: PgPool) {
	let pool = setup_tasks.await;

	// Step 1: Create new task
	let task = Task::new(
		"Implement login feature".to_string(),
		"Add user authentication with JWT".to_string(),
		"todo".to_string(),
		1,                                                         // High priority
		Some(5),                                                   // Assignee ID
		Some(Utc::now() + chrono::Duration::try_days(7).unwrap()), // Due in 7 days
	);

	let insert_sql = Query::insert()
		.into_table(Tasks::Table)
		.columns([
			Tasks::Title,
			Tasks::Description,
			Tasks::Status,
			Tasks::Priority,
			Tasks::AssigneeId,
			Tasks::DueDate,
		])
		.values_panic([
			task.title.into(),
			task.description.into(),
			task.status.into(),
			task.priority.into(),
			task.assignee_id.into(),
			task.due_date.into(),
		])
		.returning_all()
		.build(PostgresQueryBuilder);

	let row = sqlx::query(&insert_sql).fetch_one(&pool).await.unwrap();
	let task_id: i64 = row.get("id");
	let initial_status: String = row.get("status");

	assert_eq!(initial_status, "todo");

	// Step 2: Start working on task
	let start_sql = Query::update()
		.table(Tasks::Table)
		.values([(Tasks::Status, "in_progress".into())])
		.and_where(sea_query::Expr::col(Tasks::Id).eq(task_id))
		.build(PostgresQueryBuilder);

	sqlx::query(&start_sql).execute(&pool).await.unwrap();

	// Step 3: Complete task
	let complete_sql = Query::update()
		.table(Tasks::Table)
		.values([(Tasks::Status, "done".into())])
		.and_where(sea_query::Expr::col(Tasks::Id).eq(task_id))
		.build(PostgresQueryBuilder);

	sqlx::query(&complete_sql).execute(&pool).await.unwrap();

	// Verify task completed
	let select_sql = Query::select()
		.from(Tasks::Table)
		.column(Tasks::Status)
		.and_where(sea_query::Expr::col(Tasks::Id).eq(task_id))
		.build(PostgresQueryBuilder);

	let completed_row = sqlx::query(&select_sql).fetch_one(&pool).await.unwrap();
	let final_status: String = completed_row.get("status");

	assert_eq!(final_status, "done");
}

/// Use Case 4: Product search and filtering
#[rstest]
#[tokio::test]
#[serial(views_usecases)]
async fn test_product_search_filtering(#[future] setup_products: PgPool) {
	let pool = setup_products.await;

	// Insert multiple products
	for i in 1..=10 {
		let product = Product::new(
			format!("Product {}", i),
			format!("SKU-{:03}", i),
			(i as f64) * 10.0,
			i * 5,
			if i % 2 == 0 { "Electronics" } else { "Books" }.to_string(),
			i % 3 != 0, // Some inactive products
		);

		let insert_sql = Query::insert()
			.into_table(Products::Table)
			.columns([
				Products::Name,
				Products::Sku,
				Products::Price,
				Products::StockQuantity,
				Products::Category,
				Products::Active,
			])
			.values_panic([
				product.name.into(),
				product.sku.into(),
				product.price.into(),
				product.stock_quantity.into(),
				product.category.into(),
				product.active.into(),
			])
			.build(PostgresQueryBuilder);

		sqlx::query(&insert_sql).execute(&pool).await.unwrap();
	}

	// Search: Active Electronics products with price < 50
	let search_sql = Query::select()
		.from(Products::Table)
		.columns([
			Products::Id,
			Products::Name,
			Products::Category,
			Products::Price,
		])
		.and_where(sea_query::Expr::col(Products::Category).eq("Electronics"))
		.and_where(sea_query::Expr::col(Products::Active).eq(true))
		.and_where(sea_query::Expr::col(Products::Price).lt(50.0))
		.order_by(Products::Price, sea_query::Order::Asc)
		.build(PostgresQueryBuilder);

	let rows = sqlx::query(&search_sql).fetch_all(&pool).await.unwrap();

	// Verify all results match criteria
	for row in rows {
		let category: String = row.get("category");
		let price: f64 = row.get("price");

		assert_eq!(category, "Electronics");
		assert!(price < 50.0, "Price should be less than 50");
	}
}

/// Use Case 5: Bulk task creation for project
#[rstest]
#[tokio::test]
#[serial(views_usecases)]
async fn test_bulk_task_creation(#[future] setup_tasks: PgPool) {
	let pool = setup_tasks.await;

	// Create multiple tasks for a project
	let task_titles = vec![
		"Design database schema",
		"Implement API endpoints",
		"Write unit tests",
		"Create documentation",
		"Deploy to staging",
	];

	for (index, title) in task_titles.iter().enumerate() {
		let task = Task::new(
			title.to_string(),
			format!("Description for {}", title),
			"todo".to_string(),
			(index as i32) + 1, // Priority based on order
			Some(1),            // Assignee
			Some(Utc::now() + chrono::Duration::try_days((index as i64) + 1).unwrap()),
		);

		let insert_sql = Query::insert()
			.into_table(Tasks::Table)
			.columns([
				Tasks::Title,
				Tasks::Description,
				Tasks::Status,
				Tasks::Priority,
				Tasks::AssigneeId,
				Tasks::DueDate,
			])
			.values_panic([
				task.title.into(),
				task.description.into(),
				task.status.into(),
				task.priority.into(),
				task.assignee_id.into(),
				task.due_date.into(),
			])
			.build(PostgresQueryBuilder);

		sqlx::query(&insert_sql).execute(&pool).await.unwrap();
	}

	// Verify all tasks created
	let count_sql = Query::select()
		.from(Tasks::Table)
		.expr(sea_query::Func::count(sea_query::Expr::col(Tasks::Id)))
		.build(PostgresQueryBuilder);

	let count_row = sqlx::query(&count_sql).fetch_one(&pool).await.unwrap();
	let task_count: i64 = count_row.get(0);

	assert_eq!(task_count, 5, "Should have created 5 tasks");
}

/// Use Case 6: Category-based content organization
#[rstest]
#[tokio::test]
#[serial(views_usecases)]
async fn test_category_based_organization(#[future] setup_blog: PgPool) {
	let pool = setup_blog.await;

	// Insert posts in different categories (simulated with status field)
	let categories = vec!["Technology", "Travel", "Food", "Technology", "Travel"];

	for (index, category) in categories.iter().enumerate() {
		let post = BlogPost::new(
			format!("Post about {}", category),
			format!("Content for {} post {}", category, index),
			category.to_string(), // Using status field as category for this test
			Some(1),
			if category == &"Technology" {
				Some(Utc::now())
			} else {
				None
			},
			Some(Utc::now()),
		);

		let insert_sql = Query::insert()
			.into_table(BlogPosts::Table)
			.columns([
				BlogPosts::Title,
				BlogPosts::Content,
				BlogPosts::Status,
				BlogPosts::AuthorId,
				BlogPosts::PublishedAt,
				BlogPosts::CreatedAt,
			])
			.values_panic([
				post.title.into(),
				post.content.into(),
				post.status.into(),
				post.author_id.into(),
				post.published_at.into(),
				post.created_at.into(),
			])
			.build(PostgresQueryBuilder);

		sqlx::query(&insert_sql).execute(&pool).await.unwrap();
	}

	// Query: Get all Technology posts
	let tech_posts_sql = Query::select()
		.from(BlogPosts::Table)
		.columns([BlogPosts::Id, BlogPosts::Title, BlogPosts::Status])
		.and_where(sea_query::Expr::col(BlogPosts::Status).eq("Technology"))
		.build(PostgresQueryBuilder);

	let tech_rows = sqlx::query(&tech_posts_sql).fetch_all(&pool).await.unwrap();

	assert_eq!(tech_rows.len(), 2, "Should have 2 Technology posts");

	// Verify all are Technology category
	for row in tech_rows {
		let status: String = row.get("status");
		assert_eq!(status, "Technology");
	}
}

/// Use Case 7: Multi-tenant product isolation
#[rstest]
#[tokio::test]
#[serial(views_usecases)]
async fn test_multi_tenant_isolation(#[future] setup_products: PgPool) {
	let pool = setup_products.await;

	// Insert products for different "tenants" (simulated with category field)
	let tenant_products = vec![
		("Tenant A", "Product A1"),
		("Tenant A", "Product A2"),
		("Tenant B", "Product B1"),
		("Tenant B", "Product B2"),
		("Tenant C", "Product C1"),
	];

	for (index, (tenant, name)) in tenant_products.iter().enumerate() {
		let product = Product::new(
			name.to_string(),
			format!("SKU-{}", index),
			99.99,
			10,
			tenant.to_string(), // Using category as tenant identifier
			true,
		);

		let insert_sql = Query::insert()
			.into_table(Products::Table)
			.columns([
				Products::Name,
				Products::Sku,
				Products::Price,
				Products::StockQuantity,
				Products::Category,
				Products::Active,
			])
			.values_panic([
				product.name.into(),
				product.sku.into(),
				product.price.into(),
				product.stock_quantity.into(),
				product.category.into(),
				product.active.into(),
			])
			.build(PostgresQueryBuilder);

		sqlx::query(&insert_sql).execute(&pool).await.unwrap();
	}

	// Query: Get only Tenant A products
	let tenant_a_sql = Query::select()
		.from(Products::Table)
		.columns([Products::Id, Products::Name, Products::Category])
		.and_where(sea_query::Expr::col(Products::Category).eq("Tenant A"))
		.build(PostgresQueryBuilder);

	let tenant_a_rows = sqlx::query(&tenant_a_sql).fetch_all(&pool).await.unwrap();

	assert_eq!(tenant_a_rows.len(), 2, "Tenant A should have 2 products");

	// Verify isolation - no products from other tenants
	for row in tenant_a_rows {
		let category: String = row.get("category");
		assert_eq!(category, "Tenant A");
	}
}
